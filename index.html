<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Technoscientific Practices of Music</title>
    <link
    rel="icon"
    type="image/x-icon"
    href="assets/icon.png"
  />
  <meta property="’og:title’" content="Technoscientific Practices of Music; New Technologies, Instruments and Agents" />
  <meta property="’og:image’" content="assets/cover.png" />
  <meta
    property="’og:description’"
    content="New music technologies as a process / practice / relationship that involves social and technoscientific transformations in view of music, science, philosophy, community of people, non-humans and life-world as a whole"
  />
  <meta property="’og:url’" content="" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="627" />
  <meta property="og:type" content="website" />

    <link rel="stylesheet" href="style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <script src="script.js" async></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Spline+Sans+Mono:ital,wght@0,300;0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&family=Spline+Sans:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <!-- CSS only -->
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-gH2yIJqKdNHPEq0n4Mqa/HGKIhSkIHeL5AyhkYV8i59U5AR6csBvApHHNl/vI1Bx"
      crossorigin="anonymous"
    />
  </head>
  <body>
    <nav class="navbar fixed-top navbar-dark bg-dark">
      <div class="menu_header">
        <a class="menu_anchor" href="#speakers_anchor">Invited Speakers</a>
        <a class="menu_anchor" href="#programme_anchor">Programme</a>
        <a class="menu_anchor" href="mailto:koray.tahiroglu@aalto.fi?subject=Symposium on Technoscientific Practices of Music - November 2022">Contact</a>
        <!-- <a class="menu_anchor d-none d-sm-block" href='https://link.webropolsurveys.com/EP/1C8DC6994F291A74' target="_blank" style="color: var(--yellow)!important;">Register</a> -->
      </div>
    </nav>
    <div class="landing">
      <div id="myImage">
      </div>
        <video autoplay muted loop playsinline id="myVideo" class="d-none d-lg-block">
            <source src="assets/screenLG.mp4" type="video/mp4">
            <source src="assets/screenLG.webm" type="video/webm">
          </video>
    
        <video autoplay muted loop playsinline id="myVideo" class="d-lg-none" poster="http://dmi.aalto.fi/symposium22/assets/poster.png">
            <source src="assets/screenSM.mp4" type="video/mp4">
            <source src="assets/screenSM.webm" type="video/webm">
          </video>
      
   
      <div class="landing_info" id="sound_sketch">
          <span id="symposium">symposium</span>
        <h1 class="title">Technoscientific </br>Practices of Music;</h1>
        <h2 class="subtitle">New Technologies, Instruments and Agents</h2>
        <!-- <button id="register_button" onclick="window.location.href='https://link.webropolsurveys.com/EP/1C8DC6994F291A74';" target="_blank">Register!</button> -->
<div class="basic_info">
    <div class="info_item"><h5 class="info">Nov. 11th 2022</h5></span></div>
    <div class="info_item"><h5 class="info">Oodi - Helsinki, Finland</h5></div>
    <div class="info_item"><h5 class="info">Open public event</h5></div>
</div>
        <p class="d-none d-md-block"> The symposium will discuss the <strong>new music technologies</strong> as a process / practice / relationship that involves <strong>social and technoscientific  transformations</strong> in view of music, science, philosophy, community of people, non-humans and life-world as a whole. It is not anymore a myth or urban legend, advanced <strong>AI technologies</strong> do challenge current  practices of creative practitioners and offer a <strong>new perspective</strong> that redefines the relation between humans and AI.  What does this say about the nature of AI and its ability to be part of the <strong> mutual incorporation</strong>? What “social connections” these AI creative agents build up in music practices, which leads to <strong> emerging aesthetics and meanings</strong> to appear that would not have been possible otherwise.</p>
        <div class="logos_info">
            <div class="logo_item"><img class="logo" src="assets/aalto-side-logo.png"/></div>
            <div class="logo_item"><img class="logo" src="assets/aka-logo2.png"/></div>
            <div class="logo_item margin_left"><img class="logo" src="assets/adc-side-logo.png"/></div>
        </div>
      </div>
    </div>
    <div class="bg_opacity">
    <div class="container-lg left">
        <section class="d-md-none">
     
 <p>
  The symposium will discuss the <strong>new music technologies</strong> as a process / practice / relationship that involves <strong>social and technoscientific  transformations</strong> in view of music, science, philosophy, community of people, non-humans and life-world as a whole. It is not anymore a myth or urban legend, advanced <strong>AI technologies</strong> do challenge current  practices of creative practitioners and offer a <strong>new perspective</strong> that redefines the relation between humans and AI.  What does this say about the nature of AI and its ability to be part of the <strong> mutual incorporation</strong>? What “social connections” these AI creative agents build up in music practices, which leads to <strong> emerging aesthetics and meanings</strong> to appear that would not have been possible otherwise.
 </p>
    </section>
    <div id="speakers_anchor" class="anchor_points"></div>
    <section>
        <div class="section_title">
      <h2 class="subsection" style="color: var(--purple);">Invited Speakers</h2>
      <img class="border_bottom" src="assets/line-purple.png">

    </div>
    <p style="color: var(--purple);margin-top: -14px;"><i>Alphabetically in surname</i></p>
      <div class="row">
     
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture"src="assets/adnan.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Adnan Marquez Borbon</h4>
            <h6 class="speaker_inst">Autonomous University of Baja California, Mexico</h6>
            <p>
            Currently serves as an Assistant Professor at the Faculty of Arts, Autonomous University of Baja California (UABC) Campus Ensenada.<span id="dots">...</span><span id="more"> His work has been published in the New Instruments for Musical Expression (NIME) international conference, Computer Music Journal and Critical Studies in Improvisation / Études critiques en improvisation Journal. In 2018 he was recipient of the Art, Science and Technology (ACT) grant awarded by the Mexican Secretary of Culture, the National Fund For Culture And The Arts and theNational Autonomous University of Mexico. He is co-founder and leader of the Arts and Technology Laboratory (LATe-UABC).<br>Adnan Marquez-Borbon holds a PhD from the Sonic Arts Research Center (SARC) at Queen's University Belfast, Northern Ireland. His areas of interest are sound art, interactive audiovisual system design, human factors in performer-computer interaction, processes and practices of improvisation, learning processes and technologically mediated pedagogy of the arts.</span>
              <button class="read_more" onclick="myFunction()" id="myBtn">+</button>
            </p>
      
          </div>
        </div>
    </div>
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/georgina.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Georgina Born</h4>
            <h6 class="speaker_inst">University College London</h6>
            <p>
              Georgina Born OBE FBA is Professor of Anthropology and Music, University College London. Earlier, she worked as a musician with <span id="dots1">...</span><span id="more1">avant-garde rock, jazz and improvising groups.  Her work combines ethnographic and theoretical writings on music, sound, television and digital media. Her books include Rationalizing Culture: IRCAM, Boulez, and the Institutionalization of the Musical Avant-Garde (California, 1995), Western Music and Its Other (California, 2000), Music, Sound and Space (Cambridge, 20013), Interdisciplinarity (Routledge, 2013), and Improvisation and Social Aesthetics (Duke, 2017). She directed the European Research Council funded research program ‘Music, Digitization, Mediation’ and has been a visiting professor at UC Berkeley, UC Irvine, and McGill, Hong Kong, Oslo and Aarhus Universities.</span>
                <button class="read_more" onclick="myFunction1()" id="myBtn1">+</button>
              </p>
          </div>
        </div>
        </div>
      
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/rebecca.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Rebecca Fiebrink</h4>
            <h6 class="speaker_inst">University of the Arts London</h6>
            <p>
              I am a Professor at the UAL Creative Computing Institute. My students, research assistants, and I work on a variety of projects developing  <span id="dots2">...</span><span id="more2">new technologies to enable new forms of human expression, creativity, and embodied interaction.
                 Much of my current research combines techniques from human-computer interaction, machine learning, and signal processing to allow people to apply machine learning more effectively to new problems, such as the design of new digital musical instruments and gestural interfaces for gaming and accessibility. I am also involved in projects developing rich interactive technologies for digital humanities scholarship, and machine learning education. I am the creator of the <a href="http://www.wekinator.org/" target="_blank">Wekinator</a> tool for real-time interactive machine learning and teach the Machine Learning for Musicians and Artists course on <a href="https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info" target="_blank">Kadenze</a>.</span>
                <button class="read_more" onclick="myFunction2()" id="myBtn2">+</button>
              </p>
        </div>
          </div>
        </div>
  
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/owen.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Owen Green</h4>
            <h6 class="speaker_inst">University of Huddersfield</h6>
            <p>Owen Green is an improviser, composer, performer, and systems-maker.<span id="dots3">...</span><span id="more3">He does unspeakable things with cardboard and machine listening technologies, as well as more speakable things alongside other humans, including the groups RawGreenRust (with Jules Rawlinson and Dave Murray Rust) and Sileni (with Ali Maloney). Owen has worked as a Research Fellow in Creative Coding at the University of Huddersfield on the Fluid Corpus Manipulation project, which aims to help other people do things with machine listening.</span>
                <button class="read_more" onclick="myFunction3()" id="myBtn3">+</button>
              </p>
        </div>
          </div>
        </div>
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/michael.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Michael Gurevich</h4>
            <h6 class="speaker_inst">University of Michigan</h6>
            <p>
              Michael Gurevich’s highly interdisciplinary research employs diverse methodologies to explore new aesthetic and interactional <span id="dots4">...</span><span id="more4">possibilities that can emerge in music performance with real-time computer systems.His recent research has focused on the technological mediation of human relationships around music creation and performance, incorporating technologies including telematics, mechatronic, and motion capture to examine concepts of gesture, skill, style, and instrumentality. His creative practice explores many of the same themes, through experimental compositions involving interactive media, sound installations, and the design of new musical interfaces. His book manuscript in progress is focused on documenting the cultural, technological, and aesthetic contexts for the emergence of computer music in Silicon Valley. He is Associate Professor of Performing Arts Technology at the University of Michigan’s School of Music, Theatre and Dance, where he teaches courses in physical computing, electronic music performance, and interdisciplinary collaboration. He holds a Bachelor of Music with high distinction in Computer Applications in Music from McGill University in Montréal, Canada, as well as an M.A. and Ph.D. from the Center for Computer Research in Music and Acoustics (CCRMA) at Stanford University. Professor Gurevich is an active author and editor in the New Interfaces for Musical Expression (NIME), computer music, and human-computer interaction (HCI) communities. 
              </span>
                <button class="read_more" onclick="myFunction4()" id="myBtn4">+</button>
              </p>
        </div>
          </div>
        </div>

        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/laurens.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Laurens van der Heijden</h4>
            <h6 class="speaker_inst">University of Twente</h6>
            <p>
              Laurens van der Heijden studied art history and musicology at Leiden University and Utrecht University and continued his studies with <span id="dots5">...</span><span id="more5">musicologist Reinhold Brinkmann at the Harvard University music department. He entered the record industry and held positions in marketing and sales of the classical, jazz and worldmusic repertoire.
                He worked for Dutch national public radio and television (NPS) as editor/editor-in- chief, was jazzproducer of the Metropole Orkest and travelled through the African continent producing documentaries on ethnic folklore. Subsequently he held the position of music director/general manager at a large theatre and concerthall organization. Over the last decade Laurens van der Heijden has lectured at the Academy of Music of ArtEZ University of the Arts. Besides teaching cultural philosophy and philosophy of sound in the Master’s programme ‘The Sound of Innovation’, he lectures on the history of jazz and popmusic and provides introductory seminars on ethnic folklore. At present he is preparing his dissertation with philosopher of technology Peter-Paul Verbeek (University of Twente), exploring digital music technology from the perspective of postphenomenology.</span>
                <button class="read_more" onclick="myFunction5()" id="myBtn5">+</button>
              </p>
        </div>
          </div>
        </div>
    
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/anna.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Anna Xambó Sedó</h4>
            <h6 class="speaker_inst">De Montfort University</h6>
            <p>
              Anna Xambó is a Senior Lecturer in Music and Audio Technology at De Montfort University (DMU), a member of Music, Technology <span id="dots6">...</span><span id="more6">and Innovation - Institute for Sonic Creativity (MTI2), and an experimental electronic music producer.  Her research and practice focus on sound and music computing systems looking at novel approaches to collaborative, participatory, and live coding experiences. She has been the Principal Investigator of the EPSRC HDI Network Plus funded project "MIRLCAuto: A Virtual Agent for Music Information Retrieval in Live Coding" and part of the Future Research Leaders Programme 2021/22 at DMU. Since 2016, she has taken proactive roles in organisations for improving the representation of women in music technology. https://annaxambo.me</span>
                <button class="read_more" onclick="myFunction6()" id="myBtn6">+</button>
              </p>
        </div>
          </div>
        </div>
        <div class="speaker col-md-6 col-sm-10 col-12 align_center">
            <div class="row">
          <div class="col-4"><img class="picture" src="assets/koray.jpg"></div>
          <div class="col-8 speaker_info">
            <h4 class="speaker_name">Koray Tahiroğlu</h4>
            <h6 class="speaker_inst">Aalto University</h6>
            <p>
              Koray Tahiroğlu is a musician, Academy Research Fellow and lecturer in the Department of Art and Media, Aalto University School of ARTS. <span id="dots7">...</span><span id="more7"> He is the founder and head of SOPI (Sound and Physical Interaction) research group, coordinating research projects with interests including embodied approaches to sonic interaction, new interfaces for musical expression, deep learning and artificial intelligence (AI) technologies with audio. Since 2004, he has been also teaching workshops and courses introducing artistic strategies and methodologies for creating interactive music. Tahiroğlu has performed music in collaboration as well as in solo performances in Europe, North America and Australia. His work has been presented in important venues, such as Ars Electronica, AI x Music Festival, STEIM, TodaysArt and Audio Art Festival. In 2018, he was awarded a 5-year Academy of Finland Research Fellowship.</span>
                <button class="read_more" onclick="myFunction7()" id="myBtn7">+</button>
              </p>
        </div>
          </div>
        </div>
      </div>
    </section>
    <div id="programme_anchor" class="anchor_points"></div>
    <section>
        <div class="section_title">
            <h2 class="subsection" style="color: var(--yellow);">Programme</h2>
            <img class="border_bottom" src="assets/line-yellow.png">
          </div>
          <!-- <h4>Coming soon!</h4> -->
      <div class="row">
        <div class="col-12 col-md-6">
          <!-- <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">9:30</span></h4></div><div class="col-sm-10 col-11 align_center"><h4>Coffee</h4>
            <h6 class="extra_info"></h6></div>
          </div> -->
          <!-- <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">10:00</span></h4></div><div class="col-sm-10 col-11 align_center"><h4>Welcome</h4>
            <h6 class="extra_info"></h6></div>
          </div> -->
          <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">10:10</span></h4></div>
            <div class="col-sm-10 col-11 align_center"><h4>Music Technology Research, Its Publics and Its Discontents </h4>
            <h6 class="extra_info">Owen Green</h6>
            <div class="embedded_video">
              <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            </div>

            <p>This talk will reflect critically on the aspirations and outcomes of a recent five-year musical techno-scientific project <span id="dots8">...</span><span id="more8"> called Fluid Corpus Manipulation, and use this reflection as a springboard to thinking about the nature of the publics that Music Technology research addresses. This project's focus was on putting signal processing and data scientific tools into the hands of creative coding musician-researchers, and so the impulse is to frame thinking about it in terms of its techno-scientific productivity: what tools, artifacts, theories, and so on came out of the research. What happens if instead we think of it as an episode of cultural production, specifically musical cultural production? I'll argue that from such a framing what emerges a renewed impression of Music Technology's incoherence as a research field, and that one dimension of this incoherence is in who the 'publics' for this research could be, and that confronting such a question offers possible escapes from tendencies towards techno- and market-fatalism, as well as a richer basis through which to think about our accountability as researchers. 
            </span>
                <button class="read_more" onclick="myFunction8()" id="myBtn8">+</button>
            </p>
          </div>
        </div>
          <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">10:30</span></h4></div>
            <div class="col-sm-10 col-11 align_center"><h4>HCI meets AI in Live Coding: A Practitioner's Perspective</h4>
            <h6 class="extra_info">Anna Xambó Sedó</h6>
            <div class="embedded_video">
              <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            </div>
            <p>Live coding can be seen as an improvisational practice that uses code to express ideas.<span id="dots9">...</span><span id="more9"> The potential of using AI in live coding is promising but the consequences are still unclear. This talk will reflect on the possibilities of AI in live coding as well as the potential role of live coding in the age of AI based on the lessons learned from using MIRLCAuto, a constrained live-coding environment in development by the author. MIRLCAuto works as a customisable sampler of crowdsourced sounds empowered with machine learning. The talk will focus on discussing the relevance of adopting HCI strategies to help understand the system’s behaviour. Three salient aspects will be considered: the interactional space between human agency and machine agency; interactive machine learning connected to ownership and transparency of the system; and the live-coding practice as a research tool.</span>
              <button class="read_more" onclick="myFunction9()" id="myBtn9">+</button>
          </p>
        </div>
          </div>
          <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">10:50</span></h4></div>
            <div class="col-sm-10 col-11 align_center"><h4>(Dis)Embodied Mechatronic Displays for Telematic Performance</h4>
            <h6 class="extra_info">Michael Gurevich	</h6>
            <div class="embedded_video">
              <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            </div>
            <p>Chamber musicians use a variety of bodily movements to coordinate their performance and evoke meanings for audiences,<span id="dots10">...</span><span id="more10"> ranging from subtle expressive gestures to large-scale synchronization cues. In an ongoing practice-led project involving a series of design experiments and public workshop performances, we are attempting to efficiently sense, encode, transmit, and display relevant movement features using 3-dimensional mechatronic displays to support musicians performing telematically—in disparate geographical locations using high-quality audio streamed over the Internet. The unfolding process of developing performances with these systems has shed light on musicians’ ability to form fluid and flexible relationships with mechatronic systems, which can be considered on a continuum between passive kinetic sculptures and embodied robotic avatars. This process has prompted intriguing questions about the degrees of agency, autonomy, and anthropomorphism we ascribe to materially embodied representations of ourselves and others.</span>
              <button class="read_more" onclick="myFunction10()" id="myBtn10">+</button>
          </p>
        </div>
          </div>
          <div class="schedule_item row">
            <div class="col-2 text_right"><h4><span class="time">11:10</span></h4></div>
            <div class="col-sm-10 col-11 align_center"><h4>Postphenomenological Reflections on Otherness and Artificial Intelligence in a Musical Instrument; an Exploration of Relationalities Between Hands and Giving out of Hand. </h4>
            <h6 class="extra_info">   Laurens van der Heijden</h6>
            <div class="embedded_video">
              <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
            </div>
            <p>The identification of human-technology relations (re)shapes our understanding,<span id="dots11">...</span><span id="more11"> activities and interactions we develop with digital musical instruments. In that vein, postphenomenology broadens our comprehension of more advanced configurations of digital musical instruments as agents or actors in music performances from a situated and embodied perspective. This presentation explores and questions how we can think about musical instruments -and playing them- in terms of relationalities. In line with this attitude of observation, digital musical instruments and musical instrument with artificial intelligence will be reflected. The fundamental tactile relationship with the instrument through the hands of the performer and the embeddedness in AI of the relationship between instrument, performer and sound lay bare fascinating multi-layered modes of  ‘otherness’ (alterity) touching upon crucial questions on musicianship and transformative musical practices. Postphenomenology intends us to understand, beyond the dichotomy of the human and non-human, the relationship between humans, technology and the world. Thinking from the assumption that (technical) instruments -having become part of our perception- mediate how we relate to the world, a next step would be to understand musical instruments in a likewise manner. Navigating between the affordance of the materiality of interfaces, manual manipulation and extended creativity, these new musical instruments invite us to reflect on creating new sounds with AI in between these tactile hands and the aspect of giving out of hand of the musical process. 
              </span>
              <button class="read_more" onclick="myFunction11()" id="myBtn11">+</button>
          </p>
          </div>
        </div>
        </div>
       
        <div class="col-12 col-md-6">
            <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">11:30</span></h4></div>
              <div class="col-sm-10 col-11 align_center"><h4>Mutual Dependence and Interdependence Relationships with Intelligent Artificial Entities</h4>
              <h6 class="extra_info">Koray Tahiroğlu</h6>
              <div class="embedded_video">
                <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
              </div>
              <p>The notion of intelligent entities, agency and autonomy that is implemented in artificial intelligence systems<span id="dots12">...</span><span id="more12"> used in music performances today does not imply super-powered omnipotence of a technology, but, as the title suggests, simply appears to be a part of the complex, social, mutual rather than an object of technology that is removed from the flow of the musical activity. In my talk I will discuss how co-creation practices in music make mutual dependence and interdependence relationships more explicit between human and non-human actors. To explore this co-creation concept, I will take as my starting point the studio sessions that we recorded live in March 2022 with an artificial intelligence musical instrument. These studio sessions present a way of composing and performing in which musicians have been directed to explore and re-construing their own experience in the relationship with each other and with the autonomous musical instrument. This presentation will suggest that such artificial intelligent entities become present to be agents or actors on the means of their fundamental creative acts in music.</span>
                  <button class="read_more" onclick="myFunction12()" id="myBtn12">+</button>
                </p>
            </div>
          </div>
          
            <!-- <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">11:50</span></h4></div><div class="col-sm-10 col-11 align_center"><h4>Lunch Break</h4>
              <h6 class="extra_info"></h6></div>
            </div> -->
            <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">13:00</span></h4></div>
              <div class="col-sm-10 col-11 align_center"><h4>Data, Truth, and Intention in Creative Machine Learning</h4>
              <h6 class="extra_info"> Rebecca Fiebrink</h6>
              <div class="embedded_video">
                <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
              </div>
              <p>Machine learning algorithms are, fundamentally, tools for identifying and using patterns in data.<span id="dots13">...</span><span id="more13"> Conventionally, data is understood as capturing something “true” about the world, and ML models become a way to understand or harness that truth, for instance to make better decisions, or to generate new content conforming to complex conventions. Consequently, bias in data is seen as an undesirable corruption of the truth, and models capable of capturing complex patterns in bigger datasets are understood to be more useful. However, I will argue that it is useful to think about “data” not as something “true”, but as a sort of interface between people and machines. Data embodies and communicates a set of decisions about what one would like a computer to do, what content or behaviours are important, what resources are worth expending, and more. I’ll describe how this recognition can shape how we build interactions with machine learning, design user interfaces for working with ML and data, and reckon with concepts such as bias, scale, and generality in ways that are meaningful and distinct for practitioners in music and the arts. </span>
                <button class="read_more" onclick="myFunction13()" id="myBtn13">+</button>
            </p>
            </div></div>
            <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">13:20</span></h4></div>
              <div class="col-sm-10 col-11 align_center"><h4>Views from the South: How Local Music Technology Practices from Latin America can Inform Sustainability</h4>
              <h6 class="extra_info"> Adnan Marquez-Borbon</h6>
              <div class="embedded_video">
                <div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/514201580?h=11dcef25a6&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
              </div>
              <p>In this talk, I present some examples of local technological-based artistic practices emerging from different parts of Latin America<span id="dots14">...</span><span id="more14"> reliant on the reuse and re-appropriation of materials, as well as improvisation for their problem-solving. Specifically, I will discuss how sociocultural and economic contexts constrain such artistic activities, as exemplified by the Brazilian practice of gambiarra. I will further show how electronics recycling not only has become a necessity for sustainability, but has existed as a long-standing reality within these regions. As a result, this perspective has become ingrained within these cultures. Finally, I will suggest how mainstream music and arts technology practices can benefit these approaches emerging from Latin America.</span>
                <button class="read_more" onclick="myFunction14()" id="myBtn14">+</button>
            </p>
            </div></div>
            <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">14:00</span></h4></div>
              <div class="col-sm-10 col-11 align_center"><h4>Open Panel Discussion </h4>
              <h6 class="extra_info"> All speakers</h6>
            </div></div>

            <div class="row">
              <div class="col-2 text_right"><h4><span class="time cross">13:40</span></h4></div>
              <div class="col-sm-10 col-11 align_center"><h4><span class="cross">Legacies on Conceptualising Material Agency: Do They Hold Up for Machine Learning?</span></h4>
              <h6 class="extra_info">    Georgina Born // CANCELLED //</h6>
              <p>In this conceptual, ground-clearing paper I will take a number of perspectives on the vital question of human and<span id="dots15">...</span><span id="more15">material or machine agency from anthropology, philosophy, and science and technology studies and hold them up against the new challenges posed by machine learning. The aim is to clarify, by systematically questioning, whether these well-known paradigms – inter alia, Latour and Barad, Ingold and Suchman – continue to have insights or reach their limits, and in what ways, when it comes to conceptualising our relationship with ML. I do not know in advance how this exercise will fall out, as befits the emergent nature of our knowledge of ML. But the questions are ones, it seems to me, that we need to ask. Music will be a vehicle for this process of questioning.</span>
                <button class="read_more" onclick="myFunction15()" id="myBtn15">+</button>
            </p>
            </div></div>
            <!-- <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">13:40</span></h4></div><div class="col-sm-10 col-11 align_center"><h4>Break</h4>
              <h6 class="extra_info"></h6></div>
            </div> -->
     
            <!-- <div class="schedule_item row">
              <div class="col-2 text_right"><h4><span class="time">16:00</span></h4></div><div class="col-sm-10 col-11 align_center"><h4>End of the event</h4>
              <h6 class="extra_info"> </h6>
            </div></div> -->
          </div>
      </div>
    </section>
    <!-- <div id="contact_anchor" class="anchor_points"></div>
    <section>
        <div class="section_title">
            <h2 class="subsection" style="color: var(--green);">Contact</h2>
            <img class="border_bottom" src="assets/line-green.png">
          </div>
          <h4>Please feel free to contact for any futher inquiries:</h4>
           <h4><a href="mailto:koray.tahiroglu@aalto.fi?subject=Symposium on Technoscientific Practices of Music - November 2022">Koray Tahiroğlu</a></h4>
          <h6><a href="mailto:koray.tahiroglu@aalto.fi?subject=Symposium on Technoscientific Practices of Music - November 2022">koray.tahiroglu@aalto.fi</a></h6> 
           <h6 class="extra_info2">Aalto University</h6>
           <h6 class="extra_info2">School of ARTS</h6>
           <h6 class="extra_info2"> Department of Art and Media</h6>
    </section> -->
    </div>
</div>
<div class="foot">

</div>
  </body>
  <footer>

    <!-- JavaScript Bundle with Popper -->
    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-A3rJD856KowSb7dwlZdYEkO39Gagi7vIsF0jrRAoQmDKKtQBHUuLZ9AsSv4jD4Xa"
      crossorigin="anonymous"
    ></script>
  </footer>
</html>
